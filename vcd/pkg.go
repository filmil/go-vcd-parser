package vcd

import (
	"fmt"
	"strings"

	"github.com/alecthomas/participle"
	"github.com/alecthomas/participle/v2/lexer"
)

// VCDFile represents a parsed Value Change Dump.
// The inline definition here, is based on the IEEE Std 1364-2001 Version C,
// page 331.
type VCDFile struct {
	Pos lexer.Position

	DeclarationCommand []*DeclarationCommandT `@@*`
	SimulationCommand  []*SimulationCommandT  `@@*`
}

type DeclarationCommandT struct {
	Pos lexer.Position

	CommentText string `@KwComment @String* @KwEnd`
	Date        string `| @KwDate @String @KwEnd`
	//DeclarationKeyword DeclarationKeywordT `@@`
	//CommandText        *string             `(@String) @KwEnd?`
}

type DeclarationKeywordT struct {
	Pos lexer.Position

	Comment        bool `"@KwComment"`
	Date           bool `| "@KwDate"`
	EndDefinitions bool `| "@KwEnddefinitions"`
	Scope          bool `| "@KwScope"`
	Timescale      bool `| "@KwTimescale"`
	Upscope        bool `| "@KwUpscope"`
	Var            bool `| "@KwVar"`
	Version        bool `| "@KwVersion"`
}
type SimulationCommandT struct {
	Pos lexer.Position

	SimulationCommand1 SimulationCommand1T `@@`
	SimulationTime     SimulationTimeT     `| @@`
	ValueChange        ValueChangeT        `| @@`
}

type SimulationCommand1T struct {
	Pos lexer.Position

	SimulationKeyword SimulationKeywordT `@@`
	ValueChange       []*ValueChangeT    `@@*`
	End               bool               `@KwEnd`
}

type SimulationKeywordT struct {
	Pos lexer.Position

	DumpAll  bool `@KwDumpall`
	DumpOff  bool `| @KwDumpoff`
	DumpOn   bool `| @KwDumpon`
	DumpVars bool `| @KwDumpvars`
}

type SimulationTimeT struct {
	Pos lexer.Position

	DecimalNumber string `@Timestamp`
}

type ValueChangeT struct {
	Pos lexer.Position

	ScalarValueChange *ScalarValueChangeT `@@`
	VectorValueChange *VectorValueChangeT `| @@`
}

type ScalarValueChangeT struct {
	Pos lexer.Position

	Value          ValueT `@@`
	IdentifierCode string `| @String`
}

type ValueT struct {
	Pos lexer.Position

	Value string `@("0" | "1" | "x" | "X"| "z" | "Z")`
}

type VectorValueChangeT struct {
	Pos lexer.Position

	VectorValueChange1 *VectorValueChange1T `@@`
	VectorValueChange3 *VectorValueChange3T `| @@`
}

type VectorValueChange1T struct {
	Pos lexer.Position

	BinaryNumber   string `@Binstring`
	IdentifierCode string `@String`
}

type VectorValueChange3T struct {
	Pos lexer.Position

	RealNumber     string `@RealString`
	IdentifierCode string `@String`
}

const (
	BinstringPattern  = `[bB]([10xXzZ])+`
	FloatPattern      = `[+-]?([0-9]*\.?[0-9]+|[0-9]+\.?[0-9]*)([eE][+-]?[0-9]+)?` // Generated by Gemini.
	RealStringPattern = `[r|R]` + FloatPattern
	IntPattern        = `[+-]?[0-9]+`
	StringPattern     = `\w+`
	TimestampPattern  = `#\d+`
)

// IntoRule converts a SimpleRule into a (complex) Rule.
func IntoRule(rules []lexer.SimpleRule) []lexer.Rule {
	var ret []lexer.Rule
	for _, r := range rules {
		newRule := lexer.Rule{
			Name:    r.Name,
			Pattern: r.Pattern,
			Action:  nil,
		}
		ret = append(ret, newRule)
	}
	return ret
}

func GenKeywordTokens() []lexer.SimpleRule {
	var keywords = []string{
		"end", "comment", "date", "enddefinitions", "scope", "timescale",
		"upscope", "var", "version", "dumpall", "dumpon", "dumpoff", "dumpvars",
	}

	var ret []lexer.SimpleRule
	for _, kw := range keywords {
		ret = append(ret, lexer.SimpleRule{
			Name: fmt.Sprintf("Kw%v", strings.Title(kw)),
			// Don't forget to escape your `$`
			Pattern: fmt.Sprintf(`\$%v`, kw),
		})
	}
	return ret
}

var rules = []lexer.SimpleRule{
	{
		Name:    "Timestamp",
		Pattern: TimestampPattern,
	},
	{
		Name:    "Binstring",
		Pattern: BinstringPattern,
	},
	{
		Name:    "RealString",
		Pattern: RealStringPattern,
	},
	{
		Name:    "Int",
		Pattern: IntPattern,
	},
	{
		Name:    "Float",
		Pattern: FloatPattern,
	},
	{
		Name:    "String",
		Pattern: StringPattern,
	},
	{
		Name:    "whitespace",
		Pattern: `\s+`,
	},
}

var basicLexer = lexer.MustSimple(
	// Careful about ordering here. First match is accepted.
	func() []lexer.SimpleRule {
		ret := append(GenKeywordTokens(), rules...)
		//fmt.Printf("ret: %+v", ret)
		return ret
	}(),
)

// SimpleRules returns keywords plus basic token types.
func SimpleRules() []lexer.Rule {
	ret := append(GenKeywordTokens(), rules...)
	//fmt.Printf("ret: %+v", ret)
	return IntoRule(ret)
}

func NewLexer() *lexer.StatefulDefinition {
	return lexer.MustStateful(lexer.Rules{
		"Root": SimpleRules(),
	})
}

func NewParser() *participle.Parser[VCDFile] {
	// Needs a lexer definition.
	return participle.MustBuild[VCDFile](participle.Lexer(NewLexer()))
}
